import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import linear_kernel

# Load movie data (replace with your actual data source)
# Example: df = pd.read_csv('movies_data.csv')
# Ensure 'overview' or a similar text field for content description exists
data = {'title': ['Movie A', 'Movie B', 'Movie C', 'Movie D'],
        'genres': ['Action|Sci-Fi', 'Comedy|Romance', 'Action|Thriller', 'Sci-Fi|Adventure'],
        'overview': ['A thrilling action movie with futuristic elements.',
                     'A lighthearted romantic comedy.',
                     'An intense thriller with unexpected twists.',
                     'An epic sci-fi adventure in space.']}
df = pd.DataFrame(data)

# Create a TF-IDF Vectorizer to convert text data into numerical features
tfidf = TfidfVectorizer(stop_words='english')
df['overview'] = df['overview'].fillna('') # Handle missing values
tfidf_matrix = tfidf.fit_transform(df['overview'])

# Compute the cosine similarity matrix
cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)

# Function to get recommendations
def get_recommendations_content_based(title, cosine_sim=cosine_sim, df=df):
    idx = df[df['title'] == title].index[0]
    sim_scores = list(enumerate(cosine_sim[idx]))
    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)
    sim_scores = sim_scores[1:11] # Get top 10 similar movies (excluding itself)
    movie_indices = [i[0] for i in sim_scores]
    return df['title'].iloc[movie_indices]

# Example usage:
# print(get_recommendations_content_based
